{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d965b3d",
   "metadata": {},
   "source": [
    "# HF Accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc85e220",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f296f7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "import time, gc, torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7c0e18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/opt-6.7b\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side='left')\n",
    "kwargs = dict(\n",
    "    torch_dtype=torch.float16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "451a958c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c9098a714734a3e8ece150c4fa81a28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name, **kwargs)\n",
    "model = model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "39ef9e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [\"In a galaxy far, far away\"] * BATCH_SIZE\n",
    "input_tokens = tokenizer.batch_encode_plus(inputs, return_tensors=\"pt\", padding=True)\n",
    "for t in input_tokens:\n",
    "    if torch.is_tensor(input_tokens[t]):\n",
    "        input_tokens[t] = input_tokens[t].to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e23695c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generate_kwargs = dict(max_new_tokens=100, use_cache=True, do_sample=False)\n",
    "output_tokens = model.generate(**input_tokens, **generate_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b008809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['</s>In a galaxy far, far away, the Empire is still a thing.\\n\\nThe latest Star Wars: The Rise of Skywalker trailer is here, and it’s packed with new footage from the upcoming film.\\n\\nThe trailer opens with Rey (Daisy Ridley) and Finn (John Boyega) on a desert planet, where they’re being chased by a group of Stormtroopers.\\n\\n“We’re not going to make it,” Finn says.\\n\\n“We', '</s>In a galaxy far, far away, the Empire is still a thing.\\n\\nThe latest Star Wars: The Rise of Skywalker trailer is here, and it’s packed with new footage from the upcoming film.\\n\\nThe trailer opens with Rey (Daisy Ridley) and Finn (John Boyega) on a desert planet, where they’re being chased by a group of Stormtroopers.\\n\\n“We’re not going to make it,” Finn says.\\n\\n“We', '</s>In a galaxy far, far away, the Empire is still a thing.\\n\\nThe latest Star Wars: The Rise of Skywalker trailer is here, and it’s packed with new footage from the upcoming film.\\n\\nThe trailer opens with Rey (Daisy Ridley) and Finn (John Boyega) on a desert planet, where they’re being chased by a group of Stormtroopers.\\n\\n“We’re not going to make it,” Finn says.\\n\\n“We', '</s>In a galaxy far, far away, the Empire is still a thing.\\n\\nThe latest Star Wars: The Rise of Skywalker trailer is here, and it’s packed with new footage from the upcoming film.\\n\\nThe trailer opens with Rey (Daisy Ridley) and Finn (John Boyega) on a desert planet, where they’re being chased by a group of Stormtroopers.\\n\\n“We’re not going to make it,” Finn says.\\n\\n“We']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.batch_decode(output_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6974eff",
   "metadata": {},
   "source": [
    "### RECREATING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a8efc7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0f0263a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_saver = {}\n",
    "# shapes = [10, 128, 256, 512, 1024]\n",
    "shapes = [512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "27d1ea53",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 1024/1024 [00:28<00:00, 35.48it/s]\n"
     ]
    }
   ],
   "source": [
    "model_kwargs = model.generation_config.update(**input_tokens, **generate_kwargs)\n",
    "inputs_tensor, model_input_name, model_kwargs = model._prepare_model_inputs(\n",
    "    None, model.generation_config.bos_token_id, model_kwargs\n",
    ")\n",
    "model_kwargs[\"attention_mask\"] = model._prepare_attention_mask_for_generation(\n",
    "    inputs_tensor, model.generation_config.pad_token_id, model.generation_config.eos_token_id\n",
    ")\n",
    "model_kwargs[\"output_attentions\"] = model.generation_config.output_attentions\n",
    "model_kwargs[\"output_hidden_states\"] = model.generation_config.output_hidden_states\n",
    "model_kwargs[\"use_cache\"] = model.generation_config.use_cache\n",
    "\n",
    "input_ids = inputs_tensor\n",
    "\n",
    "model = model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(1024)):\n",
    "        if input_ids.shape[1] in shapes:\n",
    "            inputs_saver[input_ids.shape[1]] = {\n",
    "                \"model_kwargs\": model_kwargs.copy(),\n",
    "                \"input_ids\": input_ids,\n",
    "            }\n",
    "        \n",
    "        model_inputs = model.prepare_inputs_for_generation(input_ids, **model_kwargs)\n",
    "        \n",
    "        outputs = model(\n",
    "            **model_inputs, \n",
    "            return_dict=True,\n",
    "            output_attentions=model.generation_config.output_attentions,\n",
    "            output_hidden_states=model.generation_config.output_hidden_states)\n",
    "\n",
    "        next_token_logits = outputs.logits[:, -1, :]\n",
    "\n",
    "        next_tokens = torch.argmax(next_token_logits, dim=-1)\n",
    "        input_ids = torch.cat([input_ids, next_tokens[:, None]], dim=-1)\n",
    "        model_kwargs = model._update_model_kwargs_for_generation(\n",
    "            outputs, model_kwargs, is_encoder_decoder=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5e3388e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 32, 511, 128])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_saver[512][\"model_kwargs\"][\"past_key_values\"][0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836d9166",
   "metadata": {},
   "source": [
    "## PROFILING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "87fe479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3136952a",
   "metadata": {},
   "source": [
    "### DECODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "23d4e5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KV Cache Shape: torch.Size([4, 32, 511, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 37.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode with input_ids.shape = torch.Size([4, 512])\n",
      "Time:  2.69\n",
      "Iterations: 100\n",
      "Throughput (tokens/sec):  148.48\n",
      "Latency (sec/inference):  0.027\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "iterations = 100\n",
    "for shape in shapes:\n",
    "    input_ids = inputs_saver[shape][\"input_ids\"]\n",
    "    model_kwargs = inputs_saver[shape][\"model_kwargs\"]\n",
    "    model_inputs = model.prepare_inputs_for_generation(input_ids, **model_kwargs)\n",
    "   \n",
    "    with torch.no_grad():\n",
    "        start = time.perf_counter()\n",
    "\n",
    "        print(f'KV Cache Shape: {model_inputs[\"past_key_values\"][0][0].shape}')\n",
    "        for it in tqdm(range(iterations)):\n",
    "            outputs = model(\n",
    "                **model_inputs, \n",
    "                return_dict=True,\n",
    "                output_attentions=model.generation_config.output_attentions,\n",
    "                output_hidden_states=model.generation_config.output_hidden_states)\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        end = time.perf_counter()\n",
    "    \n",
    "    print(f\"Decode with input_ids.shape = {input_ids.shape}\")\n",
    "    batch = input_ids.shape[0]\n",
    "    print(f\"Time: {end-start: .2f}\")\n",
    "    print(f\"Iterations: {iterations}\")\n",
    "    print(f\"Throughput (tokens/sec): {(iterations * batch) / (end-start) : .2f}\")\n",
    "    print(f\"Latency (sec/inference): {(end-start) / iterations : .3f}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3cf47a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aebf141",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
